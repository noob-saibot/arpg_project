{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "import gym\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from typing import NamedTuple\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from policy_generator.policy_instances.envs.simple_arena import ActionSpace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device to run model on \n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ObsSpace(NamedTuple):\n",
    "    agent: np.ndarray\n",
    "    agent_direction: int\n",
    "    target: np.ndarray\n",
    "    velocity: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using a neural network to learn our policy parameters\n",
    "class QLearningNetwork(nn.Module):\n",
    "    #Takes in observations and outputs actions\n",
    "    def __init__(self, observation_space, action_space, shape):\n",
    "        super(QLearningNetwork, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(observation_space, shape),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(shape, shape),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(shape, shape),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(shape, action_space)\n",
    "        )\n",
    "    \n",
    "    #forward pass\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class QBot:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.train_config = None\n",
    "        \n",
    "    def training_config(self, **kwargs):\n",
    "        self.train_config = {\n",
    "                'discount_factor': 0.923,\n",
    "                'eps': 0.42,\n",
    "                'eps_min': 0.075,\n",
    "                'eps_decay': 0.96,\n",
    "                'learning_rate': 0.053,\n",
    "                'num_episodes': 50,\n",
    "                'batch_size': 32,\n",
    "                'network_shape': 128,\n",
    "                }\n",
    "        if kwargs:\n",
    "            self.train_config.update(**kwargs)\n",
    "            \n",
    "#             b_params = {'discount_factor': 0.9232432057242249,\n",
    "#                          'eps': 0.41987501329393667,\n",
    "#                          'eps_min': 0.07487696385957002,\n",
    "#                          'eps_decay': 0.9625856506789202,\n",
    "#                          'learning_rate': 0.052947112503709155,\n",
    "#                          'network_shape': 27}\n",
    "            \n",
    "    def _init_environment(self):\n",
    "        #Make environment\n",
    "        env = gym.make(\"policy_instances/SimpleArena-v0\")\n",
    "\n",
    "        network = QLearningNetwork(env.shape, env.action_space.n, self.train_config['network_shape']).to(DEVICE)\n",
    "\n",
    "        loss_fn = nn.MSELoss()\n",
    "        optimizer = optim.Adam(network.parameters(), lr=self.train_config['learning_rate'])\n",
    "        return env, network, loss_fn, optimizer\n",
    "    \n",
    "    def train(self, verbose=0):\n",
    "        env, network, loss_fn, optimizer = self._init_environment()\n",
    "        \n",
    "        scores = []\n",
    "\n",
    "        memory = deque(maxlen=4000)\n",
    "\n",
    "        for i in tqdm(range(self.train_config['num_episodes']), position=0, leave=True):\n",
    "            eps = self.train_config['eps']\n",
    "            state = env.reset()\n",
    "            done = False\n",
    "            eps *= self.train_config['eps_decay']\n",
    "            score = 0\n",
    "            actions_dist = []\n",
    "            #while game not ended\n",
    "            while not done:\n",
    "                env.render()\n",
    "                if isinstance(state, tuple):\n",
    "                    state = state[0]\n",
    "                #choose move with epsilon greedy\n",
    "                if np.random.random() < eps:\n",
    "                    #exploration\n",
    "                    action = np.random.randint(0, env.action_space.n)\n",
    "                else:\n",
    "                    #exploitation\n",
    "                    #use expand_dims here to add a dimension for input layer\n",
    "                    action = select_action(network, np.expand_dims(state, axis=0))[0]\n",
    "                    actions_dist.append(action)\n",
    "\n",
    "                #execute move\n",
    "                new_state, reward, done, _, _ = env.step(action)\n",
    "                score += reward\n",
    "\n",
    "                #memorize\n",
    "                memory.append([np.expand_dims(state, axis=0), action, reward, np.expand_dims(new_state, axis=0), done])\n",
    "\n",
    "                #update\n",
    "                #instead of training every state, we train in batch_size\n",
    "                if len(memory) > self.train_config['batch_size']:\n",
    "                    #sample batch_size so model could be fit on any random states in memory not just the latest state\n",
    "                    minibatch = random.sample(memory, self.train_config['batch_size'])\n",
    "                    loss = 0\n",
    "\n",
    "                    #iterate through the sampled batch\n",
    "                    for b_state, b_action, b_reward, b_new_state, b_done in minibatch:\n",
    "                        #if current game is done then target = reward cuz theres no future utility\n",
    "                        if b_done:\n",
    "                            target = b_reward\n",
    "                        else:\n",
    "                            #what we think the state's q_val should be, reward + discounted future utility\n",
    "                            target = b_reward + self.train_config['discount_factor'] * select_action(network, b_new_state)[2]\n",
    "\n",
    "                        #what we thought the current state's q_val should be\n",
    "                        target_vector = select_action(network, b_state)[1]\n",
    "\n",
    "                        #update the target_vector \n",
    "                        target_vector[0][b_action] = target\n",
    "\n",
    "                        #instead of finding temporal difference between new q_val and old q_val, we train the model by giving it the new q_val\n",
    "                        # and let the network do the updating \n",
    "                        #train the model with the batch\n",
    "                        loss = loss_fn(select_action(network, b_state)[1], target_vector)\n",
    "                        optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "\n",
    "                        step = optimizer.step()\n",
    "#                     optimizer.zero_grad()\n",
    "#                     loss.backward()\n",
    "\n",
    "#                     step = optimizer.step()\n",
    "\n",
    "                    #update epsilon\n",
    "                    if eps > self.train_config['eps_min']:\n",
    "                        eps *= self.train_config['eps_decay']\n",
    "\n",
    "                #new state\n",
    "                state = new_state\n",
    "            if verbose > 0:\n",
    "                print(score)\n",
    "                print(list(zip(*np.unique(actions_dist, return_counts=True))))\n",
    "            scores.append(score)\n",
    "        return scores\n",
    "\n",
    "            \n",
    "def select_action(network, state):\n",
    "    ''' Selects an action given current state\n",
    "    Args:\n",
    "    - network (Torch NN): network to process state\n",
    "    - state (Array): Array of action space in an environment\n",
    "    \n",
    "    Return:\n",
    "    - (int): action that is selected\n",
    "    - (float): log probability of selecting that action given state and network\n",
    "    '''\n",
    "    #convert state to float tensor, add 1 dimension, allocate tensor on device\n",
    "    state = ObsSpace(**state[0] if isinstance(state, (tuple, list, np.ndarray)) else state)\n",
    "    unpack_state = list(chain(state.agent, state.target, [state.velocity, state.agent_direction]))\n",
    "    state = torch.Tensor(unpack_state).float().unsqueeze(0).to(DEVICE)\n",
    "    \n",
    "    #use network to predict action probabilities\n",
    "    q_vals = network(state)\n",
    "    \n",
    "    #sample an action using the probability distribution\n",
    "    action = torch.argmax(q_vals)\n",
    "    max_value = torch.max(q_vals)\n",
    "    \n",
    "    #return action\n",
    "    return action.item(), q_vals, max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9035a76bcb1424b911564634073f027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-34\n",
      "[(0, 6), (1, 40), (2, 7), (4, 29)]\n",
      "26\n",
      "[(0, 12), (1, 43), (2, 16), (3, 4), (4, 15)]\n",
      "-36\n",
      "[(0, 11), (1, 35), (2, 19), (3, 8), (4, 13)]\n",
      "-28\n",
      "[(0, 11), (1, 38), (2, 13), (3, 8), (4, 16)]\n",
      "-40\n",
      "[(0, 13), (1, 33), (2, 17), (3, 9), (4, 20)]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m bot \u001b[38;5;241m=\u001b[39m QBot()\n\u001b[1;32m      2\u001b[0m bot\u001b[38;5;241m.\u001b[39mtraining_config(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_episodes\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m200\u001b[39m})\n\u001b[0;32m----> 3\u001b[0m \u001b[43mbot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [5], line 109\u001b[0m, in \u001b[0;36mQBot.train\u001b[0;34m(self, verbose)\u001b[0m\n\u001b[1;32m    106\u001b[0m     target \u001b[38;5;241m=\u001b[39m b_reward \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiscount_factor\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m select_action(network, b_new_state)[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m#what we thought the current state's q_val should be\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m target_vector \u001b[38;5;241m=\u001b[39m \u001b[43mselect_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_state\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    111\u001b[0m \u001b[38;5;66;03m#update the target_vector \u001b[39;00m\n\u001b[1;32m    112\u001b[0m target_vector[\u001b[38;5;241m0\u001b[39m][b_action] \u001b[38;5;241m=\u001b[39m target\n",
      "Cell \u001b[0;32mIn [5], line 156\u001b[0m, in \u001b[0;36mselect_action\u001b[0;34m(network, state)\u001b[0m\n\u001b[1;32m    153\u001b[0m state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor(unpack_state)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m    155\u001b[0m \u001b[38;5;66;03m#use network to predict action probabilities\u001b[39;00m\n\u001b[0;32m--> 156\u001b[0m q_vals \u001b[38;5;241m=\u001b[39m \u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m#sample an action using the probability distribution\u001b[39;00m\n\u001b[1;32m    159\u001b[0m action \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(q_vals)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn [5], line 18\u001b[0m, in \u001b[0;36mQLearningNetwork.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py:139\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 139\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1191\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_is_full_backward_hook\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m   1192\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_full_backward_hook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1194\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tensor, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModule\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m   1195\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m   1196\u001b[0m         _parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bot = QBot()\n",
    "bot.training_config(**{\"num_episodes\": 200})\n",
    "bot.train(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 12:08:52,772]\u001b[0m A new study created in memory with name: no-name-36dc40b2-ab18-4de0-b16d-0e7bbcc87e24\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c624043d44044539ad9ae88d764cb90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 12:12:12,123]\u001b[0m Trial 0 finished with value: 333.0 and parameters: {'discount_factor': 0.961149283518651, 'eps': 0.5039940575634445, 'eps_min': 0.09187487028585081, 'eps_decay': 0.9368721683610204, 'learning_rate': 0.06780245382687256, 'network_shape': 46}. Best is trial 0 with value: 333.0.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "409804ce9d904ff5ab566a2353d195e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 12:15:30,832]\u001b[0m Trial 1 finished with value: 287.25 and parameters: {'discount_factor': 0.9204618347705573, 'eps': 0.5541758911752037, 'eps_min': 0.02966008613644321, 'eps_decay': 0.9052466827620687, 'learning_rate': 0.0023205613233050378, 'network_shape': 27}. Best is trial 1 with value: 287.25.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ae4d85ee0f44784becb02e75e4867d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 12:18:15,788]\u001b[0m Trial 2 finished with value: 290.15 and parameters: {'discount_factor': 0.9657599568701325, 'eps': 0.5760968127381298, 'eps_min': 0.022180455926810384, 'eps_decay': 0.9758470524431863, 'learning_rate': 0.06805540409416005, 'network_shape': 82}. Best is trial 1 with value: 287.25.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a2aa4a6dcda4ee89d12577967b95081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 12:21:02,719]\u001b[0m Trial 3 finished with value: 357.2 and parameters: {'discount_factor': 0.9755657022088203, 'eps': 0.5026651397028264, 'eps_min': 0.08810196789618005, 'eps_decay': 0.9256995934260474, 'learning_rate': 0.06677159485268187, 'network_shape': 27}. Best is trial 1 with value: 287.25.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ae49f06ae014d64815473be32987cca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 12:23:44,732]\u001b[0m Trial 4 finished with value: 291.35 and parameters: {'discount_factor': 0.9154736206094876, 'eps': 0.5282040482250558, 'eps_min': 0.09664420840470955, 'eps_decay': 0.9541866090127227, 'learning_rate': 0.04175005796072797, 'network_shape': 46}. Best is trial 1 with value: 287.25.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a200c015d7c542ac942cccce50c56745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 12:26:16,115]\u001b[0m Trial 5 finished with value: 243.5 and parameters: {'discount_factor': 0.9232432057242249, 'eps': 0.41987501329393667, 'eps_min': 0.07487696385957002, 'eps_decay': 0.9625856506789202, 'learning_rate': 0.052947112503709155, 'network_shape': 27}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9529f06f9b9a4ff28c53834671acb10a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 12:29:03,607]\u001b[0m Trial 6 finished with value: 314.3 and parameters: {'discount_factor': 0.9868209047525768, 'eps': 0.5400615465493351, 'eps_min': 0.020663074849635824, 'eps_decay': 0.9246991413940536, 'learning_rate': 0.07993476848982771, 'network_shape': 67}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2e15e5e263141c0b76d00d6a4959978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 12:31:55,259]\u001b[0m Trial 7 finished with value: 306.7 and parameters: {'discount_factor': 0.9628895212745423, 'eps': 0.4041883969749285, 'eps_min': 0.06662333921525006, 'eps_decay': 0.9257158569469242, 'learning_rate': 0.08431223683141345, 'network_shape': 104}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f62bdddc8962454d93ed0a848c1488b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 12:34:48,741]\u001b[0m Trial 8 finished with value: 300.5 and parameters: {'discount_factor': 0.972701445799947, 'eps': 0.48564461978575524, 'eps_min': 0.05894362227766433, 'eps_decay': 0.980417836759394, 'learning_rate': 0.07235538608777568, 'network_shape': 100}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78e1f72a78db41b5b1624dfd44ee03c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 12:37:37,294]\u001b[0m Trial 9 finished with value: 284.8 and parameters: {'discount_factor': 0.9218981272306215, 'eps': 0.5274292596565957, 'eps_min': 0.024921208879632673, 'eps_decay': 0.9728961938094166, 'learning_rate': 0.050953253496474754, 'network_shape': 34}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40a642bc4bbc471dad57297bee1cd3ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 12:40:28,510]\u001b[0m Trial 10 finished with value: 312.0 and parameters: {'discount_factor': 0.9382937119557917, 'eps': 0.40040910627871346, 'eps_min': 0.07079996153507256, 'eps_decay': 0.9565450689623964, 'learning_rate': 0.022674871534790836, 'network_shape': 67}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c750bc66cc0d4c5c987be9d38121d693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 12:43:06,484]\u001b[0m Trial 11 finished with value: 259.55 and parameters: {'discount_factor': 0.9020403421283949, 'eps': 0.45260838531611824, 'eps_min': 0.04200571980399199, 'eps_decay': 0.9677347211244547, 'learning_rate': 0.04452318659690049, 'network_shape': 19}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "266df000fdb240a58d05a3d2c5703373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 12:46:10,177]\u001b[0m Trial 12 finished with value: 337.05 and parameters: {'discount_factor': 0.9024333296156373, 'eps': 0.4464886831248577, 'eps_min': 0.046468622859365386, 'eps_decay': 0.9627665705450368, 'learning_rate': 0.04202512330223472, 'network_shape': 18}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d1bfc9dc2724e0780ae85aa883400da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 12:49:27,838]\u001b[0m Trial 13 finished with value: 280.15 and parameters: {'discount_factor': 0.900527639311822, 'eps': 0.44552892504072783, 'eps_min': 0.043007392903319334, 'eps_decay': 0.9898998637765115, 'learning_rate': 0.028205780539233324, 'network_shape': 123}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc76200fce4a487e847ea134c6d84f23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 12:52:34,812]\u001b[0m Trial 14 finished with value: 285.8 and parameters: {'discount_factor': 0.9361690368371527, 'eps': 0.4424294212584185, 'eps_min': 0.007001599072509093, 'eps_decay': 0.9637444923924804, 'learning_rate': 0.09901368143375255, 'network_shape': 48}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11112d2212f3496e86f73c5ee19ad276",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 12:56:27,846]\u001b[0m Trial 15 finished with value: 292.1 and parameters: {'discount_factor': 0.9106980188405855, 'eps': 0.4700349340460984, 'eps_min': 0.07631616611539907, 'eps_decay': 0.9442749857298575, 'learning_rate': 0.05496416902124114, 'network_shape': 17}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bfd426d09a2498c97ca6e29398a0fe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 12:59:51,773]\u001b[0m Trial 16 finished with value: 308.55 and parameters: {'discount_factor': 0.9297243343899873, 'eps': 0.4258698824652537, 'eps_min': 0.038451238828430025, 'eps_decay': 0.9498841725936474, 'learning_rate': 0.026162876037118983, 'network_shape': 54}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae6e6369f34d45c38f547780982cdc0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 13:03:08,990]\u001b[0m Trial 17 finished with value: 289.5 and parameters: {'discount_factor': 0.9106002695190426, 'eps': 0.4679101458391433, 'eps_min': 0.05521292736993094, 'eps_decay': 0.9878001447323808, 'learning_rate': 0.03730962742237273, 'network_shape': 33}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e97a43ca4284b63af46a038ad7ed0a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 13:06:45,301]\u001b[0m Trial 18 finished with value: 505.8 and parameters: {'discount_factor': 0.9445001153833145, 'eps': 0.4294505544030271, 'eps_min': 0.08063505796740161, 'eps_decay': 0.9666171516290221, 'learning_rate': 0.05581853884426979, 'network_shape': 83}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a12d186aeb8420e85eb200124f81c1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 13:09:56,296]\u001b[0m Trial 19 finished with value: 323.1 and parameters: {'discount_factor': 0.9275072657267993, 'eps': 0.5976543969842596, 'eps_min': 0.06347910566561282, 'eps_decay': 0.9416328870151569, 'learning_rate': 0.011219886830063683, 'network_shape': 59}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "884346f26f014f518aed76354dfae968",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 13:12:53,189]\u001b[0m Trial 20 finished with value: 299.9 and parameters: {'discount_factor': 0.952652728536153, 'eps': 0.420203049228468, 'eps_min': 0.05077711728165197, 'eps_decay': 0.9707611054548358, 'learning_rate': 0.03611895244501147, 'network_shape': 40}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cf651f061144e65b5dea230d0e3d97c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 13:15:39,365]\u001b[0m Trial 21 finished with value: 256.55 and parameters: {'discount_factor': 0.9000415814386163, 'eps': 0.456587989850518, 'eps_min': 0.04203199406175129, 'eps_decay': 0.9862980020057288, 'learning_rate': 0.02768486309277752, 'network_shape': 114}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45dec7d77d794a509e2452fef70055f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 13:18:30,265]\u001b[0m Trial 22 finished with value: 313.95 and parameters: {'discount_factor': 0.9072753662928454, 'eps': 0.4662708596168669, 'eps_min': 0.0373415484859001, 'eps_decay': 0.9813942079123562, 'learning_rate': 0.018245174690514857, 'network_shape': 126}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb5989a4ed4747ef9d4e3eb61a090f7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 13:21:26,770]\u001b[0m Trial 23 finished with value: 267.8 and parameters: {'discount_factor': 0.9194533035760254, 'eps': 0.48399316210284793, 'eps_min': 0.03103786076313951, 'eps_decay': 0.9814570762289655, 'learning_rate': 0.04771409561624446, 'network_shape': 113}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59cebc07041943678253c4308ba3098e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 13:24:18,024]\u001b[0m Trial 24 finished with value: 268.8 and parameters: {'discount_factor': 0.9012800331669323, 'eps': 0.4607826104685591, 'eps_min': 0.010070367208906791, 'eps_decay': 0.9596626127908405, 'learning_rate': 0.05996226492844958, 'network_shape': 95}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fad269ce7fa947dea3a98aea72f86a22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 13:27:22,986]\u001b[0m Trial 25 finished with value: 270.05 and parameters: {'discount_factor': 0.9122928607921339, 'eps': 0.4183008390131988, 'eps_min': 0.05165645936944031, 'eps_decay': 0.9696403051422513, 'learning_rate': 0.03281426476286201, 'network_shape': 87}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4cfbfa62b7d46cfa86732c906201682",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 13:30:18,407]\u001b[0m Trial 26 finished with value: 329.35 and parameters: {'discount_factor': 0.9264760890719698, 'eps': 0.4382793254203726, 'eps_min': 0.08330906650323627, 'eps_decay': 0.9765816949415721, 'learning_rate': 0.018684630620693386, 'network_shape': 16}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dcb3bdb95794c21867dba6029787238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 13:33:09,362]\u001b[0m Trial 27 finished with value: 294.5 and parameters: {'discount_factor': 0.9073267742267811, 'eps': 0.45487241225147934, 'eps_min': 0.04172621730019866, 'eps_decay': 0.952524432360578, 'learning_rate': 0.04595211942905824, 'network_shape': 111}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01170a67eb5d45ba888f157a111217db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 13:36:10,264]\u001b[0m Trial 28 finished with value: 305.25 and parameters: {'discount_factor': 0.9363572617069099, 'eps': 0.4824076024799333, 'eps_min': 0.07281555599798896, 'eps_decay': 0.9845004031163413, 'learning_rate': 0.010770537021020432, 'network_shape': 26}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f54f8695875648039f73f225456195fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 13:39:12,792]\u001b[0m Trial 29 finished with value: 273.2 and parameters: {'discount_factor': 0.9165558538115819, 'eps': 0.4138259566930562, 'eps_min': 0.06102644011539608, 'eps_decay': 0.9342665323529074, 'learning_rate': 0.0352906528929673, 'network_shape': 76}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc50eeea02b1483790f109ed8401abef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 13:42:17,268]\u001b[0m Trial 30 finished with value: 302.6 and parameters: {'discount_factor': 0.9510967328014727, 'eps': 0.4928877523353116, 'eps_min': 0.01516365086271073, 'eps_decay': 0.9664775419927011, 'learning_rate': 0.06103910678061443, 'network_shape': 39}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f6be37fc50b4e9e8bc55e823d0da171",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 13:45:19,562]\u001b[0m Trial 31 finished with value: 362.2 and parameters: {'discount_factor': 0.9203687768478876, 'eps': 0.47626870164185153, 'eps_min': 0.0345160393478457, 'eps_decay': 0.978564405653511, 'learning_rate': 0.04638630191703614, 'network_shape': 115}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7afe62874ac45a289f72011e3637409",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 13:48:17,827]\u001b[0m Trial 32 finished with value: 330.25 and parameters: {'discount_factor': 0.906950892101215, 'eps': 0.5160748490191691, 'eps_min': 0.032399134950359953, 'eps_decay': 0.9853657393778402, 'learning_rate': 0.04989973982223846, 'network_shape': 112}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0243f631db59432f8e35f1dad5cf38bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 13:51:08,205]\u001b[0m Trial 33 finished with value: 269.35 and parameters: {'discount_factor': 0.9186456770554765, 'eps': 0.45440240869106774, 'eps_min': 0.04703867333546632, 'eps_decay': 0.9775742659260322, 'learning_rate': 0.02994066704438118, 'network_shape': 92}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "482fe72fbe364301b5fba06222a53580",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 13:54:01,782]\u001b[0m Trial 34 finished with value: 271.45 and parameters: {'discount_factor': 0.9244072086056627, 'eps': 0.4322863092090061, 'eps_min': 0.029096730946900903, 'eps_decay': 0.9018239744600379, 'learning_rate': 0.04225950549883806, 'network_shape': 119}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bda34bc78a544969b33acae6ea02dda9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 13:56:53,081]\u001b[0m Trial 35 finished with value: 285.55 and parameters: {'discount_factor': 0.9317242332340007, 'eps': 0.5063001407175899, 'eps_min': 0.030275069540249062, 'eps_decay': 0.9720773327449259, 'learning_rate': 0.06692193918218131, 'network_shape': 104}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31e95de590e244359ea4072d64907910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 13:59:50,120]\u001b[0m Trial 36 finished with value: 314.5 and parameters: {'discount_factor': 0.9130708689244466, 'eps': 0.49067481249556977, 'eps_min': 0.09768047979610572, 'eps_decay': 0.9840742640187423, 'learning_rate': 0.05965018613555617, 'network_shape': 26}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5744a3af160a4f8aac2c698226fcf61b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 14:02:44,666]\u001b[0m Trial 37 finished with value: 296.9 and parameters: {'discount_factor': 0.9054394862006312, 'eps': 0.45360723570576916, 'eps_min': 0.021080485690601693, 'eps_decay': 0.9587936078500843, 'learning_rate': 0.05058156949718323, 'network_shape': 76}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14036ace134f4bd4a768aa2f2e5704c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 14:05:36,986]\u001b[0m Trial 38 finished with value: 346.95 and parameters: {'discount_factor': 0.9168175949072784, 'eps': 0.5642941292950694, 'eps_min': 0.08826504954950629, 'eps_decay': 0.9738840964345181, 'learning_rate': 0.00040500787233980345, 'network_shape': 128}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77cffbb0f4224f40a3523b15956e011e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 14:08:41,844]\u001b[0m Trial 39 finished with value: 312.65 and parameters: {'discount_factor': 0.9440328343442953, 'eps': 0.41109742633107915, 'eps_min': 0.02543615038650547, 'eps_decay': 0.9899236506984791, 'learning_rate': 0.07201471323649261, 'network_shape': 105}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac185622038442fa99c9eea4b7a7f825",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 14:12:28,614]\u001b[0m Trial 40 finished with value: 272.2 and parameters: {'discount_factor': 0.9219037269100138, 'eps': 0.5044273495452218, 'eps_min': 0.0562133102419478, 'eps_decay': 0.9826067046756578, 'learning_rate': 0.07937222676946318, 'network_shape': 59}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "898bcdf30f164b9da5edba1bbddd09dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 14:15:37,896]\u001b[0m Trial 41 finished with value: 312.75 and parameters: {'discount_factor': 0.9013431734907722, 'eps': 0.4615000093739598, 'eps_min': 0.005808852407811296, 'eps_decay': 0.9608798246848349, 'learning_rate': 0.062036986229461716, 'network_shape': 93}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4803f3b65b0945f89f2d05448c059bae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 14:19:07,288]\u001b[0m Trial 42 finished with value: 294.6 and parameters: {'discount_factor': 0.9057768529022464, 'eps': 0.4786465985430229, 'eps_min': 0.014514961619319842, 'eps_decay': 0.9517135204024784, 'learning_rate': 0.055750959847004185, 'network_shape': 97}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c42d8355cea84cc691d7ec9c0489e831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 14:22:46,074]\u001b[0m Trial 43 finished with value: 343.8 and parameters: {'discount_factor': 0.900789493045145, 'eps': 0.45897788377538934, 'eps_min': 0.015252198615228724, 'eps_decay': 0.96749495696047, 'learning_rate': 0.040667975487691625, 'network_shape': 119}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c2da4fc344e4b219a6a0d4515064583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 14:26:14,987]\u001b[0m Trial 44 finished with value: 298.35 and parameters: {'discount_factor': 0.9137958022158995, 'eps': 0.4374551811633576, 'eps_min': 0.04625093647854328, 'eps_decay': 0.9477984192071232, 'learning_rate': 0.04805228255295631, 'network_shape': 108}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8c34ccaeea54250ab84ea26036e84d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 14:29:48,947]\u001b[0m Trial 45 finished with value: 317.55 and parameters: {'discount_factor': 0.9866778050962999, 'eps': 0.4737707657080069, 'eps_min': 0.04030676839287313, 'eps_decay': 0.9106943125753981, 'learning_rate': 0.06250407997686803, 'network_shape': 22}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "953f03b60c0f4ab0aa78efdb7749369f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 14:33:16,652]\u001b[0m Trial 46 finished with value: 304.6 and parameters: {'discount_factor': 0.9040969723161207, 'eps': 0.4482009409729332, 'eps_min': 0.025854325849780018, 'eps_decay': 0.9560568050383423, 'learning_rate': 0.05365657595505758, 'network_shape': 33}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f1380c127194a4ea33e666407c4de1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 14:36:34,176]\u001b[0m Trial 47 finished with value: 313.35 and parameters: {'discount_factor': 0.9097249343003336, 'eps': 0.49259441403971, 'eps_min': 0.010723752278286593, 'eps_decay': 0.9623970759463727, 'learning_rate': 0.07055394991547854, 'network_shape': 100}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbb131493f20497a99349d88bca4c152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 14:39:20,009]\u001b[0m Trial 48 finished with value: 293.8 and parameters: {'discount_factor': 0.9000826459380852, 'eps': 0.40648518877872186, 'eps_min': 0.03685284724522832, 'eps_decay': 0.9763056366298405, 'learning_rate': 0.07623923523708045, 'network_shape': 121}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb48ce4669d0420b997261ed708eb58e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 14:42:01,309]\u001b[0m Trial 49 finished with value: 381.2 and parameters: {'discount_factor': 0.9091355282062648, 'eps': 0.42726773686503433, 'eps_min': 0.06474562555167401, 'eps_decay': 0.9576879150770636, 'learning_rate': 0.04310553268499151, 'network_shape': 115}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8c6fa590eaf44b5ae5b7f92d0d5b7bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 14:44:51,687]\u001b[0m Trial 50 finished with value: 299.2 and parameters: {'discount_factor': 0.9316101195480816, 'eps': 0.517870532049557, 'eps_min': 0.04404294110616024, 'eps_decay': 0.9386275836682137, 'learning_rate': 0.022351673440121702, 'network_shape': 68}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f57fb720fdd4a8f84a516a71bf784af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 14:47:43,037]\u001b[0m Trial 51 finished with value: 312.2 and parameters: {'discount_factor': 0.9187592673143874, 'eps': 0.4493980049431178, 'eps_min': 0.048587882165265196, 'eps_decay': 0.9800207037408522, 'learning_rate': 0.0299396732238222, 'network_shape': 89}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4854d2f4b9a407e829a4373720942c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 14:50:35,274]\u001b[0m Trial 52 finished with value: 299.6 and parameters: {'discount_factor': 0.9162756494932406, 'eps': 0.46232285392364547, 'eps_min': 0.05636433031647497, 'eps_decay': 0.9743037324119515, 'learning_rate': 0.03242652930384, 'network_shape': 97}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36d82355b4db4a0bbe234b34bfcd99f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 14:53:18,601]\u001b[0m Trial 53 finished with value: 279.85 and parameters: {'discount_factor': 0.9230953650135364, 'eps': 0.44112393622353885, 'eps_min': 0.049671284593094056, 'eps_decay': 0.9646557603474704, 'learning_rate': 0.08956135245981461, 'network_shape': 88}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1b938bf10a442e1bc2020e77bae48a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 14:55:47,375]\u001b[0m Trial 54 finished with value: 254.35 and parameters: {'discount_factor': 0.9042163803103526, 'eps': 0.4831590258243272, 'eps_min': 0.04563629520407415, 'eps_decay': 0.9692136679088366, 'learning_rate': 0.039184918664191735, 'network_shape': 80}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "469e716e6e0d4413a30843c0f9724ad2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 14:58:26,343]\u001b[0m Trial 55 finished with value: 295.25 and parameters: {'discount_factor': 0.9023777662805514, 'eps': 0.48549984048866085, 'eps_min': 0.03380418503450741, 'eps_decay': 0.9681984433735727, 'learning_rate': 0.037329596348282715, 'network_shape': 82}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "002b85f52a92470b87ae638958a4361f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 15:01:05,297]\u001b[0m Trial 56 finished with value: 284.0 and parameters: {'discount_factor': 0.9037450970614067, 'eps': 0.4711076221770268, 'eps_min': 0.04386861714430511, 'eps_decay': 0.9866478393706781, 'learning_rate': 0.05790413188998715, 'network_shape': 77}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b24b299a07184bcc9794d6c24588e5ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 15:03:33,451]\u001b[0m Trial 57 finished with value: 261.85 and parameters: {'discount_factor': 0.9117066033774038, 'eps': 0.5426877866983916, 'eps_min': 0.05438511146286216, 'eps_decay': 0.9715612808838497, 'learning_rate': 0.05258922134777687, 'network_shape': 51}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c0784b582b6467ebc8d58bef8e438fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 15:06:24,961]\u001b[0m Trial 58 finished with value: 316.05 and parameters: {'discount_factor': 0.912719587973138, 'eps': 0.5543994361013974, 'eps_min': 0.05333762243865384, 'eps_decay': 0.9711386427290304, 'learning_rate': 0.039747862506020304, 'network_shape': 45}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2373d09b6a54407ea36d87261054a61e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 15:09:17,079]\u001b[0m Trial 59 finished with value: 339.55 and parameters: {'discount_factor': 0.9083720347241839, 'eps': 0.5337757470216922, 'eps_min': 0.03909478304643466, 'eps_decay': 0.9804327099374831, 'learning_rate': 0.04560285491115749, 'network_shape': 52}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bde174d8f2cc4a30accf558055f6d79a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 15:11:57,464]\u001b[0m Trial 60 finished with value: 330.15 and parameters: {'discount_factor': 0.9099906593143684, 'eps': 0.5960002381134404, 'eps_min': 0.05968865570212383, 'eps_decay': 0.9745887068550294, 'learning_rate': 0.05258845236163396, 'network_shape': 21}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d8a9ff57110424e854a089406af0c70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 15:14:42,331]\u001b[0m Trial 61 finished with value: 299.9 and parameters: {'discount_factor': 0.9044094889239448, 'eps': 0.49856878967972684, 'eps_min': 0.06906760143804301, 'eps_decay': 0.9644345921668364, 'learning_rate': 0.06379852477446413, 'network_shape': 29}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fd71532e4514e20a9ab773a8c0fdcfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 15:17:25,010]\u001b[0m Trial 62 finished with value: 269.85 and parameters: {'discount_factor': 0.9153903089615268, 'eps': 0.46777712810407096, 'eps_min': 0.0758048511826406, 'eps_decay': 0.9602905304430747, 'learning_rate': 0.04903311066969456, 'network_shape': 71}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a6bcfb0fc9f4f0481b0465a4acb910d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 15:20:19,292]\u001b[0m Trial 63 finished with value: 299.45 and parameters: {'discount_factor': 0.9001025964874425, 'eps': 0.5477350855574329, 'eps_min': 0.029233655802492115, 'eps_decay': 0.9550558965180961, 'learning_rate': 0.05743921278037831, 'network_shape': 62}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae55d7150d854ec6a2d59b85924b085d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 15:23:08,285]\u001b[0m Trial 64 finished with value: 278.9 and parameters: {'discount_factor': 0.9119250092596446, 'eps': 0.5135788259796936, 'eps_min': 0.0178849925448216, 'eps_decay': 0.967347193983475, 'learning_rate': 0.0447129299739174, 'network_shape': 39}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "942529e60e69418f82fcf08b4f3648d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 15:25:53,001]\u001b[0m Trial 65 finished with value: 360.9 and parameters: {'discount_factor': 0.9066557258796758, 'eps': 0.4806790789916853, 'eps_min': 0.09480094650007655, 'eps_decay': 0.9697696695964584, 'learning_rate': 0.025694129914588446, 'network_shape': 23}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40c132a6e55b499fb91d435623679fd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 15:28:40,265]\u001b[0m Trial 66 finished with value: 319.65 and parameters: {'discount_factor': 0.9046245306377942, 'eps': 0.4981727141745808, 'eps_min': 0.05348020487277615, 'eps_decay': 0.9782698155315969, 'learning_rate': 0.03355224562060747, 'network_shape': 83}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eb2352a490d47c09997941b5a130cd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 15:31:48,866]\u001b[0m Trial 67 finished with value: 276.25 and parameters: {'discount_factor': 0.9261019602719679, 'eps': 0.43331405277915286, 'eps_min': 0.036167798999535705, 'eps_decay': 0.9728848836178643, 'learning_rate': 0.038909634205955, 'network_shape': 43}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf6c43fe037d41528f33c2cde004214c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 15:35:29,622]\u001b[0m Trial 68 finished with value: 309.45 and parameters: {'discount_factor': 0.9603990100126655, 'eps': 0.42079334318356193, 'eps_min': 0.010017561307250462, 'eps_decay': 0.9874174851164934, 'learning_rate': 0.053270204652352264, 'network_shape': 108}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f58c06ed5194f989cc59bcb9c0b367b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 15:38:47,975]\u001b[0m Trial 69 finished with value: 247.45 and parameters: {'discount_factor': 0.9188465738665691, 'eps': 0.5777231998722732, 'eps_min': 0.0413751696725178, 'eps_decay': 0.9818785808150706, 'learning_rate': 0.06498457067052898, 'network_shape': 30}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "992fc6ae90584a07a0cc8b06691bbc9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 15:42:14,470]\u001b[0m Trial 70 finished with value: 283.15 and parameters: {'discount_factor': 0.9297355436246113, 'eps': 0.5681470393790147, 'eps_min': 0.04302313363039839, 'eps_decay': 0.9826473178739942, 'learning_rate': 0.06611018393059111, 'network_shape': 30}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcbe88afdc7a408c87ebd14972c78af6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 15:45:45,829]\u001b[0m Trial 71 finished with value: 307.4 and parameters: {'discount_factor': 0.9189630211389542, 'eps': 0.5729470788473932, 'eps_min': 0.0817187388082237, 'eps_decay': 0.9648568084559452, 'learning_rate': 0.058327836576360634, 'network_shape': 35}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2302c57266ef47b9a1cbb4943a3e892c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 15:49:17,663]\u001b[0m Trial 72 finished with value: 288.9 and parameters: {'discount_factor': 0.914134238096938, 'eps': 0.5823892771299087, 'eps_min': 0.040584377861766455, 'eps_decay': 0.9766657068125331, 'learning_rate': 0.06514569143633744, 'network_shape': 18}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc4a4f568f694f45b87bf2419da78a76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 15:52:48,091]\u001b[0m Trial 73 finished with value: 305.3 and parameters: {'discount_factor': 0.9075000109242606, 'eps': 0.5852530894906038, 'eps_min': 0.04719503183017766, 'eps_decay': 0.9853302235071416, 'learning_rate': 0.06958348445601502, 'network_shape': 50}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07ede55ac4694edba151f0799edd6591",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 15:56:02,515]\u001b[0m Trial 74 finished with value: 278.15 and parameters: {'discount_factor': 0.9029241015356163, 'eps': 0.526529435900279, 'eps_min': 0.032874792959691986, 'eps_decay': 0.9808585187176648, 'learning_rate': 0.05122393613065901, 'network_shape': 26}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3001462275664374aab47c434f4a9fcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 15:59:35,586]\u001b[0m Trial 75 finished with value: 274.85 and parameters: {'discount_factor': 0.9112573820956965, 'eps': 0.4653945781053541, 'eps_min': 0.04496400999042894, 'eps_decay': 0.9705303667350929, 'learning_rate': 0.048113939034630016, 'network_shape': 35}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de9fe519012f4520b86b192a0a78f135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-19 16:02:46,627]\u001b[0m Trial 76 finished with value: 265.9 and parameters: {'discount_factor': 0.9402241326062796, 'eps': 0.5424744667471213, 'eps_min': 0.022253502283242216, 'eps_decay': 0.961973286393732, 'learning_rate': 0.07479473831652023, 'network_shape': 79}. Best is trial 5 with value: 243.5.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df9a3e05150a45daabd6bee36bbdec84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[W 2022-09-19 16:03:39,184]\u001b[0m Trial 77 failed because of the following error: KeyboardInterrupt()\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/beast/.local/lib/python3.8/site-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_685/1136845993.py\", line 15, in objective\n",
      "    score = bot.train()\n",
      "  File \"/tmp/ipykernel_685/1305696908.py\", line 117, in train\n",
      "    loss.backward()\n",
      "  File \"/home/beast/.local/lib/python3.8/site-packages/torch/_tensor.py\", line 396, in backward\n",
      "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
      "  File \"/home/beast/.local/lib/python3.8/site-packages/torch/autograd/__init__.py\", line 173, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(score)\n\u001b[1;32m     18\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study()\n\u001b[0;32m---> 19\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m study\u001b[38;5;241m.\u001b[39mbest_params\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/optuna/study/study.py:419\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    317\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    325\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    326\u001b[0m     \u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    327\u001b[0m \n\u001b[1;32m    328\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 419\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as CircleCI).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/optuna/study/_optimize.py:234\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    230\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    233\u001b[0m ):\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/optuna/study/_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 196\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    198\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn [16], line 15\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      4\u001b[0m bot \u001b[38;5;241m=\u001b[39m QBot()\n\u001b[1;32m      5\u001b[0m bot\u001b[38;5;241m.\u001b[39mtraining_config(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiscount_factor\u001b[39m\u001b[38;5;124m'\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_float(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiscount_factor\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0.90\u001b[39m, \u001b[38;5;241m0.99\u001b[39m),\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meps\u001b[39m\u001b[38;5;124m'\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_float(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meps\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0.4\u001b[39m, \u001b[38;5;241m0.6\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnetwork_shape\u001b[39m\u001b[38;5;124m'\u001b[39m: trial\u001b[38;5;241m.\u001b[39msuggest_int(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnetwork_shape\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m128\u001b[39m),\n\u001b[1;32m     14\u001b[0m                 })\n\u001b[0;32m---> 15\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43mbot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(score)\n",
      "Cell \u001b[0;32mIn [9], line 117\u001b[0m, in \u001b[0;36mQBot.train\u001b[0;34m(self, verbose)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;66;03m# optimizer.zero_grad()\u001b[39;00m\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;66;03m# loss.backward()\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# step = optimizer.step()\u001b[39;00m\n\u001b[1;32m    116\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 117\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m step \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m#update epsilon\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    bot = QBot()\n",
    "    bot.training_config(**{\n",
    "        'discount_factor': trial.suggest_float('discount_factor', 0.90, 0.99),\n",
    "        'eps': trial.suggest_float('eps', 0.4, 0.6),\n",
    "        'eps_min': trial.suggest_float('eps_min', 0.005, 0.1),\n",
    "        'eps_decay': trial.suggest_float('eps_decay', 0.90, 0.99),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-5, 1e-1),\n",
    "        'num_episodes': 20,\n",
    "        'batch_size': 32,\n",
    "        'network_shape': trial.suggest_int('network_shape', 16, 128),\n",
    "                    })\n",
    "    score = bot.train()\n",
    "    return -1 * np.mean(score)\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'discount_factor': 0.9232432057242249,\n",
       " 'eps': 0.41987501329393667,\n",
       " 'eps_min': 0.07487696385957002,\n",
       " 'eps_decay': 0.9625856506789202,\n",
       " 'learning_rate': 0.052947112503709155,\n",
       " 'network_shape': 27}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "discount_factor = 0.95\n",
    "eps = 0.5\n",
    "eps_min = 0.01\n",
    "eps_decay = 0.99\n",
    "learning_rate = 0.8\n",
    "num_episodes = 50\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using a neural network to learn our policy parameters\n",
    "class QLearningNetwork(nn.Module):\n",
    "    \n",
    "    #Takes in observations and outputs actions\n",
    "    def __init__(self, observation_space, action_space):\n",
    "        super(QLearningNetwork, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(observation_space, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, action_space)\n",
    "        )\n",
    "    \n",
    "    #forward pass\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_action(network, state):\n",
    "    ''' Selects an action given current state\n",
    "    Args:\n",
    "    - network (Torch NN): network to process state\n",
    "    - state (Array): Array of action space in an environment\n",
    "    \n",
    "    Return:\n",
    "    - (int): action that is selected\n",
    "    - (float): log probability of selecting that action given state and network\n",
    "    '''\n",
    "    #convert state to float tensor, add 1 dimension, allocate tensor on device\n",
    "    state = ObsSpace(**state[0] if isinstance(state, (tuple, list, np.ndarray)) else state)\n",
    "    unpack_state = list(chain(state.agent, state.target, [state.velocity, state.agent_direction]))\n",
    "    state = torch.Tensor(unpack_state).float().unsqueeze(0).to(DEVICE)\n",
    "    \n",
    "    #use network to predict action probabilities\n",
    "    q_vals = network(state)\n",
    "    \n",
    "    #sample an action using the probability distribution\n",
    "    action = torch.argmax(q_vals)\n",
    "    max_value = torch.max(q_vals)\n",
    "    \n",
    "    #return action\n",
    "    return action.item(), q_vals, max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make environment\n",
    "env = gym.make(\"policy_instances/SimpleArena-v0\")\n",
    "\n",
    "network = QLearningNetwork(env.shape, env.action_space.n).to(DEVICE)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(network.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, tensor([[-49.4963, -48.6610, -49.2828, -51.9491, -49.0963]], device='cuda:0',\n",
      "       grad_fn=<AddmmBackward0>), tensor(-48.6610, device='cuda:0', grad_fn=<MaxBackward1>))\n"
     ]
    }
   ],
   "source": [
    "def check_availability():\n",
    "    state = env.reset()\n",
    "    print(select_action(network, state))\n",
    "check_availability()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da1df35aab0c498e980a09d8fb03a8d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/beast/.local/lib/python3.8/site-packages/gym/utils/passive_env_checker.py:165: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-379\n",
      "[(0, 27), (1, 6), (2, 31)]\n",
      "-511\n",
      "[(0, 11), (1, 9), (2, 63)]\n",
      "-429\n",
      "[(0, 2), (3, 6), (4, 89)]\n",
      "-446\n",
      "[(0, 1), (4, 98)]\n",
      "-380\n",
      "[(0, 14), (1, 23), (2, 14), (3, 2), (4, 47)]\n",
      "-420\n",
      "[(0, 2), (1, 8), (2, 17), (3, 54), (4, 18)]\n",
      "-385\n",
      "[(0, 18), (1, 15), (2, 22), (3, 1), (4, 45)]\n",
      "-310\n",
      "[(0, 23), (1, 20), (2, 26), (3, 7), (4, 25)]\n",
      "-375\n",
      "[(0, 10), (1, 2), (2, 25), (3, 26), (4, 37)]\n",
      "-377\n",
      "[(0, 9), (1, 9), (2, 30), (3, 28), (4, 25)]\n",
      "-376\n",
      "[(0, 3), (1, 4), (2, 23), (3, 27), (4, 43)]\n",
      "-392\n",
      "[(0, 13), (1, 7), (2, 37), (3, 11), (4, 33)]\n",
      "-429\n",
      "[(0, 17), (1, 2), (2, 46), (3, 9), (4, 26)]\n",
      "-412\n",
      "[(0, 15), (1, 4), (2, 43), (3, 22), (4, 15)]\n",
      "-361\n",
      "[(0, 13), (1, 15), (2, 22), (3, 7), (4, 43)]\n",
      "-308\n",
      "[(0, 34), (1, 13), (2, 16), (3, 15), (4, 22)]\n",
      "-370\n",
      "[(0, 18), (1, 4), (2, 8), (3, 50), (4, 20)]\n",
      "-383\n",
      "[(0, 11), (1, 4), (2, 18), (3, 22), (4, 46)]\n",
      "-385\n",
      "[(0, 12), (1, 5), (2, 10), (3, 8), (4, 66)]\n",
      "-379\n",
      "[(0, 13), (1, 14), (2, 28), (3, 5), (4, 41)]\n",
      "-377\n",
      "[(0, 12), (1, 3), (2, 14), (3, 20), (4, 51)]\n",
      "-319\n",
      "[(0, 15), (1, 6), (2, 20), (3, 32), (4, 28)]\n",
      "76\n",
      "[(0, 5), (1, 4), (3, 3), (4, 2)]\n",
      "-342\n",
      "[(0, 16), (1, 22), (2, 4), (3, 19), (4, 38)]\n",
      "-357\n",
      "[(0, 21), (1, 14), (2, 17), (3, 32), (4, 17)]\n",
      "-360\n",
      "[(0, 19), (1, 10), (2, 23), (3, 20), (4, 26)]\n",
      "-371\n",
      "[(0, 14), (1, 22), (2, 16), (3, 10), (4, 38)]\n",
      "-516\n",
      "[(0, 7), (1, 17), (2, 53), (3, 21), (4, 2)]\n",
      "-368\n",
      "[(0, 29), (1, 16), (2, 12), (3, 2), (4, 42)]\n",
      "-352\n",
      "[(0, 18), (1, 9), (2, 17), (3, 19), (4, 35)]\n",
      "-346\n",
      "[(0, 22), (1, 12), (2, 16), (3, 12), (4, 36)]\n",
      "-313\n",
      "[(0, 42), (1, 13), (2, 5), (3, 8), (4, 33)]\n",
      "-317\n",
      "[(0, 20), (1, 23), (2, 18), (3, 24), (4, 16)]\n",
      "-317\n",
      "[(0, 12), (1, 9), (2, 38), (3, 20), (4, 22)]\n",
      "-420\n",
      "[(0, 17), (1, 4), (2, 47), (3, 27), (4, 4)]\n",
      "-303\n",
      "[(0, 7), (1, 56), (2, 3), (3, 26), (4, 7)]\n",
      "-323\n",
      "[(0, 23), (1, 12), (2, 14), (3, 17), (4, 34)]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 63\u001b[0m\n\u001b[1;32m     58\u001b[0m     target_vector[\u001b[38;5;241m0\u001b[39m][b_action] \u001b[38;5;241m=\u001b[39m target\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;66;03m#instead of finding temporal difference between new q_val and old q_val, we train the model by giving it the new q_val\u001b[39;00m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# and let the network do the updating \u001b[39;00m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;66;03m#train the model with the batch\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m     loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_fn(\u001b[43mselect_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnetwork\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_state\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m], target_vector)\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# optimizer.zero_grad()\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# loss.backward()\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \n\u001b[1;32m     67\u001b[0m     \u001b[38;5;66;03m# step = optimizer.step()\u001b[39;00m\n\u001b[1;32m     68\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "Cell \u001b[0;32mIn [6], line 42\u001b[0m, in \u001b[0;36mselect_action\u001b[0;34m(network, state)\u001b[0m\n\u001b[1;32m     39\u001b[0m state \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor(unpack_state)\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m#use network to predict action probabilities\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m q_vals \u001b[38;5;241m=\u001b[39m \u001b[43mnetwork\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m#sample an action using the probability distribution\u001b[39;00m\n\u001b[1;32m     45\u001b[0m action \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(q_vals)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1125\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 1125\u001b[0m     forward_call \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_get_tracing_state() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward)\n\u001b[1;32m   1126\u001b[0m     \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m     \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m             \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "memory = deque(maxlen=4000)\n",
    "\n",
    "for i in tqdm(range(num_episodes), position=0, leave=True):\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    eps *= eps_decay\n",
    "    score = 0\n",
    "    actions_dist = []\n",
    "    #while game not ended\n",
    "    while not done:\n",
    "        env.render()\n",
    "        if isinstance(state, tuple):\n",
    "            state = state[0]\n",
    "        #choose move with epsilon greedy\n",
    "        if np.random.random() < eps:\n",
    "            #exploration\n",
    "            action = np.random.randint(0, env.action_space.n)\n",
    "        else:\n",
    "            #exploitation\n",
    "            #use expand_dims here to add a dimension for input layer\n",
    "#             q_vals = model(state_torch)#.to('cpu').detach().numpy()\n",
    "#             action = torch.argmax(q_vals).item()\n",
    "            action = select_action(network, np.expand_dims(state, axis=0))[0]\n",
    "            actions_dist.append(action)\n",
    "        \n",
    "        #execute move\n",
    "        new_state, reward, done, _, _ = env.step(action)\n",
    "        score += reward\n",
    "        \n",
    "        #modify reward so it scales with pole angle. Pole angle range [-0.418, 0.418]\n",
    "        # reward = 1 - abs(state[2])/0.418\n",
    "        \n",
    "        #memorize\n",
    "        memory.append([np.expand_dims(state, axis=0), action, reward, np.expand_dims(new_state, axis=0), done])\n",
    "        \n",
    "        #update\n",
    "        #instead of training every state, we train in batch_size\n",
    "        if len(memory) > batch_size:\n",
    "            #sample batch_size so model could be fit on any random states in memory not just the latest state\n",
    "            minibatch = random.sample(memory, batch_size)\n",
    "            loss = 0\n",
    "            \n",
    "            #iterate through the sampled batch\n",
    "            for b_state, b_action, b_reward, b_new_state, b_done in minibatch:\n",
    "                #if current game is done then target = reward cuz theres no future utility\n",
    "                if b_done:\n",
    "                    target = b_reward\n",
    "                else:\n",
    "                    #what we think the state's q_val should be, reward + discounted future utility\n",
    "                    target = b_reward + discount_factor * select_action(network, b_new_state)[2]\n",
    "                \n",
    "                #what we thought the current state's q_val should be\n",
    "                target_vector = select_action(network, b_state)[1]\n",
    "                \n",
    "                #update the target_vector \n",
    "                target_vector[0][b_action] = target\n",
    "                \n",
    "                #instead of finding temporal difference between new q_val and old q_val, we train the model by giving it the new q_val\n",
    "                # and let the network do the updating \n",
    "                #train the model with the batch\n",
    "                loss += loss_fn(select_action(network, b_state)[1], target_vector)\n",
    "                # optimizer.zero_grad()\n",
    "                # loss.backward()\n",
    "                \n",
    "                # step = optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            step = optimizer.step()\n",
    "\n",
    "            #update epsilon\n",
    "            if eps > eps_min:\n",
    "                eps *= eps_decay\n",
    "                \n",
    "        #new state\n",
    "        state = new_state\n",
    "    print(score)\n",
    "    print(list(zip(*np.unique(actions_dist, return_counts=True))))\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "plt.plot(scores)\n",
    "plt.ylabel('score')\n",
    "plt.xlabel('episodes')\n",
    "plt.title('Score of RL Agent over episodes')\n",
    "\n",
    "reg = LinearRegression().fit(np.arange(len(scores)).reshape(-1, 1), np.array(scores).reshape(-1, 1))\n",
    "y_pred = reg.predict(np.arange(len(scores)).reshape(-1, 1))\n",
    "plt.plot(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scores = []\n",
    "while len(scores) < 50:\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = select_action(network, state)[0]\n",
    "        print(action)\n",
    "\n",
    "        new_state, reward, done, _,_ = env.step(action)\n",
    "        score += reward\n",
    "        state = new_state\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(scores).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
